{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from math import cos, sin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initiating Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files...\n",
      "Calculating and Adding Cell Polygon Center...\n",
      "Build Station Meta Dict...\n",
      "Done with initial Loading.\n"
     ]
    }
   ],
   "source": [
    "from lib.preprocessor import PreProcessor\n",
    "\n",
    "pp = PreProcessor(data_path='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing Station Test Data with KNN...\n",
      "NaNs in station_test: 5085\n",
      "New NaN Count in station_test: 0\n"
     ]
    }
   ],
   "source": [
    "pp.station_knn_impute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = pp.get_station_x_y(scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(X, Y, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(X)-seq_length-1):\n",
    "        _x = X[i:(i+seq_length), :]\n",
    "        _y = Y[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149094, 5, 6)\n",
      "(149094,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "x_train, y_train = sliding_windows(x_train, y_train, 5)\n",
    "x_test, y_test = sliding_windows(x_test, y_test, 5)\n",
    "\n",
    "x_train = torch.Tensor(np.array(x_train))\n",
    "y_train = torch.Tensor(np.array(y_train))\n",
    "\n",
    "x_test = torch.Tensor(np.array(x_test))\n",
    "y_test = torch.Tensor(np.array(y_test))\n",
    "\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_data = DataLoader(train_data, batch_size=10)\n",
    "\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_data = DataLoader(test_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = 5\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(\"cuda\")\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(\"cuda\")\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at epoch: 0 = 264.6009521484375\n",
      "Test Loss at epoch: 0 = 191.1125036301818\n",
      "Train Loss at epoch: 1 = 95.82516479492188\n",
      "Test Loss at epoch: 1 = 214.64412251708654\n",
      "Train Loss at epoch: 2 = 62.277610778808594\n",
      "Test Loss at epoch: 2 = 171.79561360542817\n",
      "Train Loss at epoch: 3 = 69.77548217773438\n",
      "Test Loss at epoch: 3 = 164.6762024110653\n",
      "Train Loss at epoch: 4 = 72.7020263671875\n",
      "Test Loss at epoch: 4 = 178.02245371243882\n",
      "Train Loss at epoch: 5 = 74.71651458740234\n",
      "Test Loss at epoch: 5 = 182.2501375125349\n",
      "Train Loss at epoch: 6 = 76.45557403564453\n",
      "Test Loss at epoch: 6 = 184.82338377364235\n",
      "Train Loss at epoch: 7 = 66.67644500732422\n",
      "Test Loss at epoch: 7 = 163.94703107354596\n",
      "Train Loss at epoch: 8 = 76.87396240234375\n",
      "Test Loss at epoch: 8 = 208.65408441210982\n",
      "Train Loss at epoch: 9 = 75.22152709960938\n",
      "Test Loss at epoch: 9 = 207.46543080249208\n",
      "Train Loss at epoch: 10 = 71.62803649902344\n",
      "Test Loss at epoch: 10 = 229.03352516143116\n",
      "Train Loss at epoch: 11 = 85.7958755493164\n",
      "Test Loss at epoch: 11 = 229.5846090751859\n",
      "Train Loss at epoch: 12 = 51.78754425048828\n",
      "Test Loss at epoch: 12 = 189.64479821127586\n",
      "Train Loss at epoch: 13 = 48.07331848144531\n",
      "Test Loss at epoch: 13 = 208.66058702221437\n",
      "Train Loss at epoch: 14 = 46.06052780151367\n",
      "Test Loss at epoch: 14 = 228.0404770843271\n",
      "Train Loss at epoch: 15 = 46.150630950927734\n",
      "Test Loss at epoch: 15 = 177.9557612613303\n",
      "Train Loss at epoch: 16 = 52.091773986816406\n",
      "Test Loss at epoch: 16 = 176.34012210346734\n",
      "Train Loss at epoch: 17 = 70.23410034179688\n",
      "Test Loss at epoch: 17 = 209.441448135266\n",
      "Train Loss at epoch: 18 = 69.03816986083984\n",
      "Test Loss at epoch: 18 = 202.32886462769133\n",
      "Train Loss at epoch: 19 = 95.59158325195312\n",
      "Test Loss at epoch: 19 = 226.6243508611425\n",
      "Train Loss at epoch: 20 = 92.96634674072266\n",
      "Test Loss at epoch: 20 = 250.68262553426015\n",
      "Train Loss at epoch: 21 = 127.76919555664062\n",
      "Test Loss at epoch: 21 = 315.2522709958513\n",
      "Train Loss at epoch: 22 = 104.90865325927734\n",
      "Test Loss at epoch: 22 = 313.4444804537964\n",
      "Train Loss at epoch: 23 = 104.10816955566406\n",
      "Test Loss at epoch: 23 = 312.82213233427694\n",
      "Train Loss at epoch: 24 = 120.69450378417969\n",
      "Test Loss at epoch: 24 = 281.9477518689348\n"
     ]
    }
   ],
   "source": [
    "x = x.to(\"cuda\")\n",
    "y = y.to(\"cuda\")\n",
    "lstm = LSTM(1, 6, 100, 1).to(\"cuda\")\n",
    "loss_fn = torch.nn.MSELoss().to(\"cuda\")\n",
    "optim = torch.optim.Adam(lstm.parameters(), 0.1)\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    for xs, ys in train_data:\n",
    "        xs = xs.to(\"cuda\")\n",
    "        ys = ys.to(\"cuda\")\n",
    "        preds = lstm(xs).squeeze(1)\n",
    "        optim.zero_grad()\n",
    "        loss = loss_fn(preds, ys)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Train Loss at epoch: {epoch} = {loss.item()}\")\n",
    "        with torch.no_grad():\n",
    "            test_losses = []\n",
    "            for xstest, ystest in test_data:\n",
    "                xstest = xstest.to(\"cuda\")\n",
    "                ystest = ystest.to(\"cuda\")\n",
    "                preds_test = lstm(xstest).squeeze(1)\n",
    "                loss_test = loss_fn(preds_test, ystest)\n",
    "                test_losses.append(loss_test.item())\n",
    "            test_losses = np.array(test_losses)\n",
    "            print(f\"Test Loss at epoch: {epoch} = {np.mean(test_losses[~np.isnan(test_losses)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(6,)),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149100 samples\n",
      "Epoch 1/5\n",
      "149100/149100 [==============================] - 11s 74us/sample - loss: 105.1010\n",
      "Epoch 2/5\n",
      "149100/149100 [==============================] - 10s 68us/sample - loss: 88.8858\n",
      "Epoch 3/5\n",
      "149100/149100 [==============================] - 10s 68us/sample - loss: 86.1138\n",
      "Epoch 4/5\n",
      "149100/149100 [==============================] - 10s 68us/sample - loss: 85.0642\n",
      "Epoch 5/5\n",
      "149100/149100 [==============================] - 10s 68us/sample - loss: 83.8534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e04b42dc88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Neighbor Dict...\n",
      "Done................\n",
      "Predicting Station Data and building x y train...\n",
      "Make sure the scaler was used already.\n",
      "Done.......\n"
     ]
    }
   ],
   "source": [
    "x_cell_train, y_cell_train = pp.get_cell_x_y(model, neighbor_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_cell_train).isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 143\n",
      "58/58\r"
     ]
    }
   ],
   "source": [
    "df = pp.submission_format.copy(deep=True)\n",
    "station_x, station_ids = pp.get_station_x_pre()\n",
    "\n",
    "ci = 1\n",
    "for c in df.columns:\n",
    "    if c == 'cell_id':\n",
    "        continue\n",
    "    date = datetime.strptime(c, '%Y-%m-%d')\n",
    "    station_x[:, 3] = date.year\n",
    "    station_x[:, 4] = date.month\n",
    "    station_x[:, 5] = date.day\n",
    "    x_to_predict = pp.min_max_scaling(station_x)\n",
    "    station_prediction = model.predict(x_to_predict)\n",
    "\n",
    "    x = []\n",
    "    for ii, r in df.iterrows():\n",
    "        cell_id = r['cell_id']\n",
    "        this_x = []\n",
    "        for n in pp.neighbor_map[cell_id]:\n",
    "            this_x.append(n[1])\n",
    "            this_x.append(n[2])\n",
    "            this_x.append(n[3])\n",
    "            this_x.append(station_prediction[station_ids.index(n[0])][0])\n",
    "\n",
    "        this_x.append(date.month)\n",
    "        this_x.append(date.day)\n",
    "        x.append(np.array(this_x, dtype='float64'))\n",
    "    x = pp.cell_scaling(np.array(x, dtype='float64'))\n",
    "    pred = model2.predict(x)\n",
    "    pred = [i[0] for i in pred]\n",
    "    pred = np.array(pred, dtype='float32')\n",
    "    df.drop(c, axis=1, inplace=True)\n",
    "    df[c] = pred\n",
    "    ci += 1\n",
    "    print('%s/%s' % (ci, pp.submission_format.shape[1]), end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
