{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b43c2e9-f0e4-4050-8b60-41e08827d3f8",
   "metadata": {},
   "source": [
    "# First Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "913227aa-83e2-468c-a8fc-5746e8a409a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from math import cos, sin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48ab7618-b45e-4d26-9406-66de299d3f08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "station_metadata = pd.read_csv('data/ground_measures_metadata.csv')\n",
    "grid_geodata = gpd.read_file('data/grid_cells.geojson')\n",
    "submission_format = pd.read_csv('data/submission_format.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "measures_test = pd.read_csv('data/ground_measures_test.csv')\n",
    "measures_train = pd.read_csv('data/ground_measures_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "station_meta = {}\n",
    "for oi, r in station_metadata.iterrows():\n",
    "    station_meta[r[0]] = {\n",
    "        'elev': r['elevation_m'],\n",
    "        'lat': r['latitude'],\n",
    "        'long': r['longitude']\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from lib.date_filler import date_filler\n",
    "\n",
    "measures_train = date_filler(measures_train, dataset='train')\n",
    "measures_test = date_filler(measures_test, dataset='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "             Unnamed: 0  2013-01-01  2013-01-02  2013-01-03  2013-01-04  \\\n0              CDEC:ADM        5.90         NaN         NaN         NaN   \n1              CDEC:AGP       17.52         NaN         NaN         NaN   \n2              CDEC:ALP       12.75         NaN         NaN         NaN   \n3              CDEC:BCB        4.30         NaN         NaN         NaN   \n4              CDEC:BCH        2.88         NaN         NaN         NaN   \n..                  ...         ...         ...         ...         ...   \n695  SNOTEL:989_ID_SNTL        9.00         NaN         NaN         NaN   \n696  SNOTEL:990_WA_SNTL       27.50         NaN         NaN         NaN   \n697  SNOTEL:992_UT_SNTL        4.10         NaN         NaN         NaN   \n698  SNOTEL:998_WA_SNTL       48.40         NaN         NaN         NaN   \n699  SNOTEL:999_WA_SNTL       33.10         NaN         NaN         NaN   \n\n     2013-01-05  2013-01-06  2013-01-07  2013-01-08  2013-01-09  ...  \\\n0           NaN         NaN         NaN        5.90         NaN  ...   \n1           NaN         NaN         NaN       17.54         NaN  ...   \n2           NaN         NaN         NaN       13.32         NaN  ...   \n3           NaN         NaN         NaN        4.42         NaN  ...   \n4           NaN         NaN         NaN        3.00         NaN  ...   \n..          ...         ...         ...         ...         ...  ...   \n695         NaN         NaN         NaN       10.20         NaN  ...   \n696         NaN         NaN         NaN       29.10         NaN  ...   \n697         NaN         NaN         NaN        4.10         NaN  ...   \n698         NaN         NaN         NaN       55.50         NaN  ...   \n699         NaN         NaN         NaN       37.50         NaN  ...   \n\n     2019-12-22  2019-12-23  2019-12-24  2019-12-25  2019-12-26  2019-12-27  \\\n0           NaN         NaN        3.70         NaN         NaN         NaN   \n1           NaN         NaN         NaN         NaN         NaN         NaN   \n2           NaN         NaN       12.67         NaN         NaN         NaN   \n3           NaN         NaN         NaN         NaN         NaN         NaN   \n4           NaN         NaN        5.04         NaN         NaN         NaN   \n..          ...         ...         ...         ...         ...         ...   \n695         NaN         NaN        2.80         NaN         NaN         NaN   \n696         NaN         NaN        8.70         NaN         NaN         NaN   \n697         NaN         NaN        3.60         NaN         NaN         NaN   \n698         NaN         NaN       23.70         NaN         NaN         NaN   \n699         NaN         NaN        8.40         NaN         NaN         NaN   \n\n     2019-12-28  2019-12-29  2019-12-30  2019-12-31  \n0           NaN         NaN         NaN        3.40  \n1           NaN         NaN         NaN         NaN  \n2           NaN         NaN         NaN       12.57  \n3           NaN         NaN         NaN         NaN  \n4           NaN         NaN         NaN        6.00  \n..          ...         ...         ...         ...  \n695         NaN         NaN         NaN        3.00  \n696         NaN         NaN         NaN        8.60  \n697         NaN         NaN         NaN        3.80  \n698         NaN         NaN         NaN       25.00  \n699         NaN         NaN         NaN        9.40  \n\n[700 rows x 753 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>2013-01-01</th>\n      <th>2013-01-02</th>\n      <th>2013-01-03</th>\n      <th>2013-01-04</th>\n      <th>2013-01-05</th>\n      <th>2013-01-06</th>\n      <th>2013-01-07</th>\n      <th>2013-01-08</th>\n      <th>2013-01-09</th>\n      <th>...</th>\n      <th>2019-12-22</th>\n      <th>2019-12-23</th>\n      <th>2019-12-24</th>\n      <th>2019-12-25</th>\n      <th>2019-12-26</th>\n      <th>2019-12-27</th>\n      <th>2019-12-28</th>\n      <th>2019-12-29</th>\n      <th>2019-12-30</th>\n      <th>2019-12-31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CDEC:ADM</td>\n      <td>5.90</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.90</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CDEC:AGP</td>\n      <td>17.52</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.54</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CDEC:ALP</td>\n      <td>12.75</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.32</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.67</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.57</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CDEC:BCB</td>\n      <td>4.30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.42</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CDEC:BCH</td>\n      <td>2.88</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.00</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>695</th>\n      <td>SNOTEL:989_ID_SNTL</td>\n      <td>9.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.20</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>SNOTEL:990_WA_SNTL</td>\n      <td>27.50</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.10</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.60</td>\n    </tr>\n    <tr>\n      <th>697</th>\n      <td>SNOTEL:992_UT_SNTL</td>\n      <td>4.10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.10</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.60</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.80</td>\n    </tr>\n    <tr>\n      <th>698</th>\n      <td>SNOTEL:998_WA_SNTL</td>\n      <td>48.40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55.50</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.70</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.00</td>\n    </tr>\n    <tr>\n      <th>699</th>\n      <td>SNOTEL:999_WA_SNTL</td>\n      <td>33.10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37.50</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.40</td>\n    </tr>\n  </tbody>\n</table>\n<p>700 rows × 753 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def df_to_xy(dataframe: pd.DataFrame):\n",
    "    x = []\n",
    "    y = []\n",
    "    for oi, j in dataframe.iterrows():\n",
    "        lat = station_meta[j[0]]['lat']\n",
    "        long = station_meta[j[0]]['long']\n",
    "        elev = station_meta[j[0]]['elev']\n",
    "        for k, e in j.items():\n",
    "            if k == 'Unnamed: 0':\n",
    "                continue\n",
    "            dt = datetime.strptime(k, '%Y-%m-%d')\n",
    "            date = dt.date()\n",
    "            x.append(np.array([elev, lat, long, date.year - 2000, date.month, date.day]))\n",
    "            y.append(e)\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "x_train_pre, y_train_pre = df_to_xy(measures_train)\n",
    "x_test_pre, y_test_pre = df_to_xy(measures_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def minmaxscaler(xs):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(xs)\n",
    "    xs = scaler.transform(xs)\n",
    "    return xs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def impute_data(x_train_pre_imp, y_train_pre_imp, x_test_pre_imp, y_test_pre_imp):\n",
    "\n",
    "    # Get indices of nan-values in y_train_pre_imp and y_test_pre_imp\n",
    "    l_train = np.argwhere(np.isnan(y_train_pre_imp))\n",
    "    l_test = np.argwhere(np.isnan(y_test_pre_imp))\n",
    "    ind_train = []\n",
    "    ind_test = []\n",
    "\n",
    "    for index in l_train:\n",
    "        ind_train.append(index[0])\n",
    "    for index in l_test:\n",
    "        ind_test.append(index[0])\n",
    "\n",
    "    # create concatenated x/y dataset\n",
    "    x_1 = np.delete(x_train_pre_imp, ind_train, 0)\n",
    "    x_2 = np.delete(x_test_pre_imp, ind_test, 0)\n",
    "    y_1 = np.delete(y_train_pre_imp, ind_train, 0)\n",
    "    y_2 = np.delete(y_test_pre_imp, ind_test, 0)\n",
    "    x_train_concatenated = np.concatenate((x_1, x_2), axis=0)\n",
    "    y_train_concatenated = np.concatenate((y_1, y_2), axis=0)\n",
    "\n",
    "    # create dataset for x-values with missing y\n",
    "    x_pred = []\n",
    "    for x in ind_train:\n",
    "        x_pred.append(x_train_pre_imp[x])\n",
    "    for x in ind_test:\n",
    "        x_pred.append(x_test_pre_imp[x])\n",
    "    x_pred = np.asarray(x_pred)\n",
    "\n",
    "    # scale the dataset\n",
    "    x_train_concatenated = minmaxscaler(x_train_concatenated)\n",
    "    x_pred = minmaxscaler(x_pred)\n",
    "\n",
    "    # Create validation / train sets for model\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_concatenated, y_train_concatenated, test_size=0.05, random_state=42)\n",
    "\n",
    "    # create kNN-Regression model for predictions\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=5, algorithm='auto')\n",
    "    knn_reg.fit(x_train_concatenated, y_train_concatenated)\n",
    "\n",
    "\n",
    "\n",
    "    # Predict missing values\n",
    "    y_pred_real = knn_reg.predict(x_pred)\n",
    "\n",
    "    # put the predictions back into datasets from the beginning\n",
    "    # indices from missing values in y_train and y_test where stored in ind_train, ind_test\n",
    "    # y_pred_real has values for these indices in ascending order\n",
    "\n",
    "    # split predictions\n",
    "    values_for_y_train = y_pred_real[:len(ind_train)]\n",
    "    values_for_y_test = y_pred_real[len(ind_train):]\n",
    "\n",
    "    y_train = np.copy(y_train_pre_imp)\n",
    "    y_test = np.copy(y_test_pre_imp)\n",
    "\n",
    "    for i in range(len(ind_train)):\n",
    "        y_train[ind_train[i]] = values_for_y_train[i]\n",
    "\n",
    "    for i in range(len(ind_test)):\n",
    "        y_test[ind_test[i]] = values_for_y_test[i]\n",
    "\n",
    "    return x_train_pre_imp, y_train, x_test_pre_imp, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = impute_data(x_train_pre, y_train_pre, x_test_pre, y_test_pre)\n",
    "x = np.concatenate((x_train, x_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "x = minmaxscaler(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First Model for Station Data Forcasting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(6,)),\n",
    "    layers.Dense(10, activation='tanh'),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5130/5130 [==============================] - 6s 1ms/step - loss: 49.3834\n",
      "Epoch 2/5\n",
      "5130/5130 [==============================] - 5s 996us/step - loss: 42.0995\n",
      "Epoch 3/5\n",
      "5130/5130 [==============================] - 6s 1ms/step - loss: 39.7977\n",
      "Epoch 4/5\n",
      "5130/5130 [==============================] - 6s 1ms/step - loss: 38.0527\n",
      "Epoch 5/5\n",
      "5130/5130 [==============================] - 6s 1ms/step - loss: 36.7416\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f9e966bed60>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=5, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: \n",
      "48.48484476752558\n",
      "\n",
      "R2:\n",
      "-37.09320688610651\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print('RMSE: ')\n",
    "print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "print('\\nR2:')\n",
    "print(r2_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "geodata = gpd.read_file('data/grid_cells.geojson')\n",
    "ground_measures = pd.read_csv(\"data/ground_measures_metadata.csv\")\n",
    "submission = pd.read_csv(\"data/submission_format.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "submission[\"location\"] = np.nan\n",
    "submission[\"elev\"] = np.nan\n",
    "ids_geo = geodata[\"cell_id\"]\n",
    "ids_sub = submission[\"cell_id\"]\n",
    "ground_measures[\"coord\"] = np.empty((len(ground_measures), 0)).tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "submission[\"location\"] = geodata[ids_geo.isin(ids_sub)].reset_index()[\"geometry\"]\n",
    "\n",
    "def get_middle(pg):\n",
    "    xy = pg.exterior.coords.xy\n",
    "    x, y = xy[0], xy[1]\n",
    "    x1, x2 = x[0], x[1]\n",
    "    y1, y2 = y[0], y[1]\n",
    "    mid_x = (x1 + x2) / 2\n",
    "    mid_y = (y1 + y2) / 2\n",
    "    assert x1 <= mid_x <= x2, \"Something is off: x\"\n",
    "    assert y1 <= mid_y <= y2, \"Something is off: y\"\n",
    "    return mid_x, mid_y\n",
    "\n",
    "submission[\"location\"] = submission[\"location\"].apply(get_middle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "for i, row in ground_measures.iterrows():\n",
    "    ground_measures.at[i, \"coord\"] = (row[4], row[3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def find_closest_station(location, station_locations):\n",
    "    _min = np.inf\n",
    "    _min_idx = None\n",
    "    location = np.array(location)\n",
    "    for i in range(len(station_locations)):\n",
    "        curr_loc = np.array(station_locations[i])\n",
    "        distance = np.sum((location - curr_loc)**2)\n",
    "        if distance < _min:\n",
    "            _min = distance\n",
    "            _min_idx = i\n",
    "    return _min_idx, _min"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "for i, row in submission.iterrows():\n",
    "    location = row[-2]\n",
    "    station_locations = ground_measures[\"coord\"]\n",
    "    idx, _ = find_closest_station(location, station_locations)\n",
    "    closest_elev = ground_measures.at[idx, \"elevation_m\"]\n",
    "    submission.at[i, \"elev\"] = closest_elev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "x_test = []\n",
    "dates = list(submission.columns)[1:-2]\n",
    "for i, row in submission.iterrows():\n",
    "\n",
    "    elev = row[-1]\n",
    "    location = row[-2]\n",
    "    batched = []\n",
    "    for d in dates:\n",
    "        date = datetime.strptime(d, '%Y-%m-%d')\n",
    "        feature = np.array([elev, location[1], location[0], date.year, date.month, date.day]).reshape(1,-1)\n",
    "        scaled_feature = sc.min_max_scaling(feature)\n",
    "        batched.append(scaled_feature)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(batched).reshape(-1,6))\n",
    "for pred, d in zip(prediction, dates):\n",
    "    submission.at[i, d] = pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "submission.drop([\"elev\", \"location\"], axis=1).to_csv('second_submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}